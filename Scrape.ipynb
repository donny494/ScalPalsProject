{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "import time\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from string import ascii_lowercase\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This opens a browser that selenium can control (ie: here we'll be loading pages) to scrape websites.  Here we are using Safari, but you can also use Chrome, FireFox, and a few other browsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ[\"SELENIUM_SERVER_JAR\"] = \"selenium-server-standalone-2.48.0.jar\"\n",
    "browser = webdriver.Safari()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Scraping  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two functions were written to help clean up the code for scraping.  \n",
    "\n",
    "table_fill: takes all the data from one of the desired tables and replaces empty entries with 'NA'.  This will be helpful later on to make sure the tables merge together seamlessly.\n",
    "\n",
    "table_fill: Iterates through the table and returns a list of lists that perfectly match the size of the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def table_fill(elements):\n",
    "    vals = []\n",
    "    for elm in elements:\n",
    "        if elm.text ==\"\":\n",
    "            vals.append('NA')\n",
    "        else:\n",
    "            vals.append(elm.text)\n",
    "    return vals\n",
    "\n",
    "def table_to_list(statstable,name,headers):\n",
    "    headLen = len(headers)-1\n",
    "    new_year = []\n",
    "    if headLen > 0:\n",
    "        years = [statstable[x:x+headLen] for x in xrange(0,len(statstable),headLen)]\n",
    "        new_year = [] \n",
    "        for year in years:\n",
    "            year = [name] + year\n",
    "            new_year.append(year)\n",
    "    return new_year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get Ex-Player Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works by iterating through each letter in the alphabet and going to the respective page for players whose last name starts with that letter.  Selenium loads the link and then gets the names of the players and the links to their respective stats page.  We then iterated through the players names, went to their stats pge, and scraped the data from their 'total' table.  We add each row to the dict list and then turn that into a DataFrame once we have collected data from all the players.\n",
    "\n",
    "Two notes:\n",
    "Because of the way basketball-reference is structured, we have to scrape current players (bolded) and Ex-Players (not bolded) separately.  This section is for Ex-Players and we'll show how to do the other players later in the notebook.\n",
    "\n",
    "Additionally, depending on whether Selenium wants to work well or not, you may have to split the alphabet into a few different groups, run this loop a few times, and merge the DataFrames later.  We had to do that and will describe how to merge them later in the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "link = 'http://www.basketball-reference.com/players/%s/'\n",
    "dict_list = []\n",
    "for letter in ascii_lowercase:\n",
    "    cur_link = link % letter\n",
    "    browser.get(cur_link)\n",
    "    names = [elm.text for elm in browser.find_elements_by_xpath(\"//*[@id='players']/tbody/tr/td[1]/a\")]\n",
    "    listplayers = [elm.get_attribute('href') for elm in browser.find_elements_by_xpath(\"//*[@id='players']/tbody/tr/td[1]/a\")]\n",
    "    for i in range(len(names)):\n",
    "        browser.get(listplayers[i])\n",
    "        name = names[i]\n",
    "        headers = ['Player'] + [elm.text for elm in browser.find_elements_by_xpath('//*[@id=\"totals\"]/thead/tr/th')]\n",
    "        table = browser.find_elements_by_xpath('//*[@id=\"totals\"]/tbody/tr/td')\n",
    "        vals = table_fill(table)\n",
    "        val_list = table_to_list(vals,name,headers)\n",
    "        for val in val_list:\n",
    "            dict_list.append(dict(zip(headers,val)))\n",
    "stats = pd.DataFrame(dict_list)\n",
    "new_stats = stats.set_index(stats.Player)\n",
    "new_stats.to_csv('aiData.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get Ex-Player Salary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works very similarly to the previous section, but we are using a different xpath to get the data from the salary data. Again, you may have to split up the alphabet, run it in chunks, and merge the DataFrames.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link = 'http://www.basketball-reference.com/players/%s/'\n",
    "dict_list = []\n",
    "for letter in ascii_lowercase:\n",
    "    cur_link = link % letter\n",
    "    browser.get(cur_link)\n",
    "    names = [elm.text for elm in browser.find_elements_by_xpath(\"//*[@id='players']/tbody/tr/td[1]/a\")]\n",
    "    listplayers = [elm.get_attribute('href') for elm in browser.find_elements_by_xpath(\"//*[@id='players']/tbody/tr/td[1]/a\")]\n",
    "    for i in range(len(names)):\n",
    "        browser.get(listplayers[i])\n",
    "        name = names[i]\n",
    "        headers = ['Player'] + [elm.text for elm in browser.find_elements_by_xpath('//*[@id=\"salaries\"]/thead/tr/th')]\n",
    "        headers = headers[0:2] + [headers[-1]]\n",
    "        vals = [[name] + elm.text.split() for elm in browser.find_elements_by_xpath('//*[@id=\"salaries\"]/tbody/tr')]\n",
    "        if headers != [] and vals != []:\n",
    "            for val in vals:\n",
    "                val = val[0:2] + [val[-1]]\n",
    "                dict_list.append(dict(zip(headers,val)))\n",
    "income = pd.DataFrame(dict_list)\n",
    "new_income = income.set_index(income.Player)\n",
    "new_income.to_csv('Income.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get Ex-Player College Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we got the college data for all the Ex-Players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link = 'http://www.basketball-reference.com/players/%s/'\n",
    "dict_list = []\n",
    "for letter in ascii_lowercase:\n",
    "    cur_link = link % letter\n",
    "    browser.get(cur_link)\n",
    "    names = [elm.text for elm in browser.find_elements_by_xpath(\"//*[@id='players']/tbody/tr/td[1]/a\")]\n",
    "    listplayers = [elm.get_attribute('href') for elm in browser.find_elements_by_xpath(\"//*[@id='players']/tbody/tr/td[1]/a\")]\n",
    "    for i in range(len(names)):\n",
    "        browser.get(listplayers[i])\n",
    "        name = names[i]\n",
    "        result = browser.find_elements_by_xpath('//*[@id=\"college\"]/tbody/tr/td')\n",
    "        headers = ['Player'] + [elm.text for elm in browser.find_elements_by_xpath('//*[@id=\"college\"]/thead/tr[2]/th')]\n",
    "        vals = table_fill(result)\n",
    "        if headers != [] and vals != []:\n",
    "            val_list = table_to_list(vals,name,headers)\n",
    "            for elm in val_list:\n",
    "                dict_list.append(dict(zip(headers,elm)))\n",
    "\n",
    "college_stats = pd.DataFrame(dict_list)\n",
    "new_college_stats = college_stats.set_index(college_stats.Player)\n",
    "new_college_stats.to_csv('PastCollegeData.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get Current Player Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Ex-Player Stats.  The main difference is that we use the xpath that selects \"strong\" aspects in the html, which means bolded text.  Thus, we can rerun the old code with the new list of names and links to get all the current player stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link = 'http://www.basketball-reference.com/players/%s/'\n",
    "dict_list = []\n",
    "for letter in ascii_lowercase:\n",
    "    cur_link = link % letter\n",
    "    browser.get(cur_link)\n",
    "    bold_names = [elm.text for elm in browser.find_elements_by_xpath(\"//*[@id='players']/tbody/tr/td[1]/strong/a\")]\n",
    "    listplayersbold = [elm.get_attribute('href') for elm in browser.find_elements_by_xpath(\"//*[@id='players']/tbody/tr/td[1]/strong/a\")]\n",
    "    for i in range(len(bold_names)):\n",
    "        browser.get(listplayersbold[i])\n",
    "        name = bold_names[i]\n",
    "        headers = ['Player'] + [elm.text for elm in browser.find_elements_by_xpath('//*[@id=\"totals\"]/thead/tr/th')]\n",
    "        table = browser.find_elements_by_xpath('//*[@id=\"totals\"]/tbody/tr/td')\n",
    "        vals = table_fill(table)\n",
    "        val_list = table_to_list(vals,name,headers)\n",
    "        for val in val_list:\n",
    "            dict_list.append(dict(zip(headers,val)))\n",
    "\n",
    "cur_stats = pd.DataFrame(dict_list)\n",
    "new_cur_stats = stats.set_index(stats.Player)\n",
    "new_cur_stats.to_csv('CurData.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Current Player Salary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link = 'http://www.basketball-reference.com/players/%s/'\n",
    "dict_list = []\n",
    "for letter in ascii_lowercase:\n",
    "    cur_link = link % letter\n",
    "    browser.get(cur_link)\n",
    "    bold_names = [elm.text for elm in browser.find_elements_by_xpath(\"//*[@id='players']/tbody/tr/td[1]/strong/a\")]\n",
    "    listplayersbold = [elm.get_attribute('href') for elm in browser.find_elements_by_xpath(\"//*[@id='players']/tbody/tr/td[1]/strong/a\")]\n",
    "    for i in range(len(bold_names)):\n",
    "        browser.get(listplayersbold[i])\n",
    "        name = bold_names[i]\n",
    "        headers = ['Player'] + [elm.text for elm in browser.find_elements_by_xpath('//*[@id=\"salaries\"]/thead/tr/th')]\n",
    "        headers = headers[0:2] + [headers[-1]]\n",
    "        vals = [[name] + elm.text.split() for elm in browser.find_elements_by_xpath('//*[@id=\"salaries\"]/tbody/tr')]\n",
    "        if headers != [] and vals != []:\n",
    "            for val in vals:\n",
    "                val = val[0:2] + [val[-1]]\n",
    "                dict_list.append(dict(zip(headers,val)))\n",
    "income = pd.DataFrame(dict_list)\n",
    "new_income = income.set_index(income.Player)\n",
    "new_income.to_csv('CurPlayerIncome.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get Current Player College Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link = 'http://www.basketball-reference.com/players/%s/'\n",
    "dict_list = []\n",
    "for letter in ascii_lowercase:\n",
    "    cur_link = link % letter\n",
    "    browser.get(cur_link)\n",
    "    bold_names = [elm.text for elm in browser.find_elements_by_xpath(\"//*[@id='players']/tbody/tr/td[1]/strong/a\")]\n",
    "    listplayersbold = [elm.get_attribute('href') for elm in browser.find_elements_by_xpath(\"//*[@id='players']/tbody/tr/td[1]/strong/a\")]\n",
    "    for i in range(len(bold_names)):\n",
    "        browser.get(listplayersbold[i])\n",
    "        name = bold_names[i]\n",
    "        result = browser.find_elements_by_xpath('//*[@id=\"college\"]/tbody/tr/td')\n",
    "        headers = ['Player'] + [elm.text for elm in browser.find_elements_by_xpath('//*[@id=\"college\"]/thead/tr[2]/th')]\n",
    "        vals = table_fill(result)\n",
    "        if headers != [] and vals != []:\n",
    "            val_list = table_to_list(vals,name,headers)\n",
    "            for elm in val_list:\n",
    "                dict_list.append(dict(zip(headers,elm)))\n",
    "\n",
    "college_stats = pd.DataFrame(dict_list)\n",
    "new_college_stats = college_stats.set_index(college_stats.Player)\n",
    "new_college_stats.to_csv('PastCollegeData.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
